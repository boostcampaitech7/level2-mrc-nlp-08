{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "def load_file(file_path: Union[str, Path]) -> List[str]:\n",
    "\n",
    "    path = Path(file_path)\n",
    "\n",
    "    # JSON 파일 읽기\n",
    "    with path.open('r', encoding='utf-8') as f:\n",
    "        predictions = json.load(f)\n",
    "        \n",
    "    # dictionary 값들을 리스트로 변환\n",
    "    if not isinstance(predictions, dict):\n",
    "        raise ValueError(\"JSON 파일은 dictionary 형태여야 합니다.\")\n",
    "        \n",
    "    return list(predictions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble1 = './ensemble_predictions/sudong_clean_bm25_nbest_predictions.json'\n",
    "ensemble2 = './ensemble_predictions/sudong_clean_final_bm25_nbest_predictions.json'\n",
    "ensemble3 = './ensemble_predictions/sudong_clean_final_bm25_dpr_nbest_predictions.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble4 = './ensemble_predictions/bert_cnn_bm25.json'\n",
    "ensemble5 = './ensemble_predictions/bert_cnn_dpr.json'\n",
    "ensemble6 = './ensemble_predictions/bert_cnn_origin.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble7 = './ensemble_predictions/tina_cnn_bm25.json'\n",
    "ensemble8 = './ensemble_predictions/tina_cnn_dpr.json'\n",
    "ensemble9 = './ensemble_predictions/tina_cnn_origin.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble10 = './ensemble_predictions/sudong_origin_bm25.json'\n",
    "ensemble11 = './ensemble_predictions/sudong_origin_dpr.json'\n",
    "ensemble12 = './ensemble_predictions/sudong_origin.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "def ensemble_predictions(prediction_files: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    여러 모델의 nbest_predictions.json 파일을 앙상블하여 최적의 답변을 도출합니다.\n",
    "    \n",
    "    Args:\n",
    "        prediction_files (List[str]): nbest_predictions.json 파일들의 경로 리스트\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, str]: 각 질문 ID에 대한 최적의 답변\n",
    "    \"\"\"\n",
    "    # 모든 예측을 저장할 딕셔너리\n",
    "    all_predictions = defaultdict(lambda: defaultdict(float))\n",
    "    \n",
    "    # 각 파일의 예측을 처리\n",
    "    for file_path in prediction_files:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            predictions = json.load(f)\n",
    "            \n",
    "        # 각 질문 ID에 대한 예측을 처리\n",
    "        for question_id, answers in predictions.items():\n",
    "            for answer in answers:\n",
    "                text = answer['text']\n",
    "                prob = answer['probability']\n",
    "                # 같은 텍스트에 대한 확률을 더함\n",
    "                all_predictions[question_id][text] += prob\n",
    "    \n",
    "    # 최종 결과를 저장할 딕셔너리\n",
    "    final_predictions = {}\n",
    "    \n",
    "    # 각 질문에 대해 가장 높은 확률을 가진 답변 선택\n",
    "    for question_id, text_probs in all_predictions.items():\n",
    "        # 가장 높은 확률을 가진 텍스트 선택\n",
    "        best_text = max(text_probs.items(), key=lambda x: x[1])[0]\n",
    "        final_predictions[question_id] = best_text\n",
    "    \n",
    "    return final_predictions\n",
    "\n",
    "def save_predictions(predictions: Dict[str, str], output_file: str):\n",
    "    \"\"\"\n",
    "    최종 예측 결과를 JSON 파일로 저장합니다.\n",
    "    \n",
    "    Args:\n",
    "        predictions (Dict[str, str]): 최종 예측 결과\n",
    "        output_file (str): 저장할 파일 경로\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(predictions, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    # 예측 파일 리스트\n",
    "    prediction_files = [\n",
    "        ensemble1,\n",
    "        ensemble2,\n",
    "        ensemble3,\n",
    "        ensemble4,\n",
    "        ensemble5,\n",
    "        ensemble6,\n",
    "        ensemble7,\n",
    "        ensemble8,\n",
    "        ensemble9,\n",
    "        ensemble10,\n",
    "        ensemble11,\n",
    "        ensemble12,\n",
    "    ]\n",
    "    \n",
    "    # 앙상블 수행\n",
    "    final_predictions = ensemble_predictions(prediction_files)\n",
    "    \n",
    "    # 결과 저장\n",
    "    save_predictions(final_predictions, \"ensemble_predictions_second.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
