{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 서로 다른 아키텍처"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## json 파일 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "def load_file(file_path: Union[str, Path]) -> List[str]:\n",
    "\n",
    "    path = Path(file_path)\n",
    "\n",
    "    # JSON 파일 읽기\n",
    "    with path.open('r', encoding='utf-8') as f:\n",
    "        predictions = json.load(f)\n",
    "        \n",
    "    # dictionary 값들을 리스트로 변환\n",
    "    if not isinstance(predictions, dict):\n",
    "        raise ValueError(\"JSON 파일은 dictionary 형태여야 합니다.\")\n",
    "        \n",
    "    return list(predictions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = './resources/checkpoint/extraction/origin/eeeyounglee_kpfbert-korquad-1/predictions.json'\n",
    "roberta = './resources/checkpoint/extraction/origin/hongzoh_roberta-large-qa-korquad-v1_batch32/predictions.json'\n",
    "kobigbird = './resources/checkpoint/extraction/origin/YuJungSoo_kobigbird-pure45-19926792/predictions.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = load_file(bert)\n",
    "roberta = load_file(roberta)\n",
    "kobigbird = load_file(kobigbird)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 답 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "valid = load_from_disk('./resources/data/train_dataset/validation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "valid_df = pd.DataFrame(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answers_text_df = valid_df[['question', 'answers']].copy()\n",
    "question_answers_text_df['answers_text'] = question_answers_text_df['answers'].apply(lambda x: x['text'])\n",
    "answers = question_answers_text_df[['answers_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = [ans[0] for ans in answers['answers_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT - RoBERTa: 0.544\n",
      "RoBERTa - KoBigBird: 0.528\n",
      "BERT - KoBigBird: 0.515\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "def calculate_error_correlations(predictions_dict: Dict[str, List[str]], \n",
    "                               answers: List[str],\n",
    "                               save_path: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    여러 모델의 predictions와 정답을 비교하여 에러 상관계수를 계산하고 시각화합니다.\n",
    "    \n",
    "    Args:\n",
    "        predictions_dict: Dict[str, List[str]] - 각 모델별 예측값 딕셔너리\n",
    "            - key: 모델 이름\n",
    "            - value: 예측값 리스트\n",
    "        answers: List[str] - 정답 리스트\n",
    "        save_path: str - 히트맵 저장 경로 (선택사항)\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame - 에러 상관계수 행렬\n",
    "    \"\"\"\n",
    "    # 각 모델의 에러 패턴을 저장할 딕셔너리 (1: 오답, 0: 정답)\n",
    "    error_patterns = {}\n",
    "    \n",
    "    # 각 모델별 에러 패턴 계산\n",
    "    for model_name, preds in predictions_dict.items():\n",
    "        errors = []\n",
    "        for pred, ans in zip(preds, answers):\n",
    "            # EM 기준으로 정답 여부 판단 (정답:0, 오답:1)\n",
    "            is_error = 0 if pred == ans else 1\n",
    "            errors.append(is_error)\n",
    "        error_patterns[model_name] = errors\n",
    "    \n",
    "    # 에러 패턴을 DataFrame으로 변환\n",
    "    error_df = pd.DataFrame(error_patterns)\n",
    "    \n",
    "    # 에러 상관계수 계산\n",
    "    correlation_matrix = error_df.corr()\n",
    "    \n",
    "    return correlation_matrix\n",
    "\n",
    "def analyze_model_pairs(correlation_matrix: pd.DataFrame, \n",
    "                       threshold: float = 0.5) -> List[tuple]:\n",
    "    \"\"\"\n",
    "    상관계수가 높은 모델 쌍을 찾아 반환합니다.\n",
    "    \n",
    "    Args:\n",
    "        correlation_matrix: pd.DataFrame - 에러 상관계수 행렬\n",
    "        threshold: float - 높은 상관관계로 판단할 기준값 (기본값: 0.5)\n",
    "    \n",
    "    Returns:\n",
    "        List[tuple] - (model1, model2, correlation) 형태의 튜플 리스트\n",
    "    \"\"\"\n",
    "    high_correlations = []\n",
    "    \n",
    "    # 상삼각 행렬만 검사 (대각선 제외)\n",
    "    for i in range(len(correlation_matrix.index)):\n",
    "        for j in range(i + 1, len(correlation_matrix.columns)):\n",
    "            correlation = correlation_matrix.iloc[i, j]\n",
    "            if abs(correlation) >= threshold:\n",
    "                model1 = correlation_matrix.index[i]\n",
    "                model2 = correlation_matrix.columns[j]\n",
    "                high_correlations.append((model1, model2, correlation))\n",
    "    \n",
    "    # 상관계수 절대값 기준으로 정렬\n",
    "    high_correlations.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "    return high_correlations\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    # 예시 데이터\n",
    "    predictions_dict = {\n",
    "        \"BERT\": bert,\n",
    "        \"RoBERTa\": roberta,\n",
    "        \"KoBigBird\": kobigbird\n",
    "    }\n",
    "    answers = answers\n",
    "    \n",
    "    # 상관계수 계산 및 시각화\n",
    "    correlation_matrix = calculate_error_correlations(\n",
    "        predictions_dict, \n",
    "        answers,\n",
    "    )\n",
    "    \n",
    "    # 높은 상관관계를 가진 모델 쌍 분석\n",
    "    high_correlations = analyze_model_pairs(correlation_matrix, threshold=0.5)\n",
    "    \n",
    "    # 결과 출력\n",
    "    for model1, model2, corr in high_correlations:\n",
    "        print(f\"{model1} - {model2}: {corr:.3f}\")\n",
    "        if corr > 0.7:\n",
    "            print(f\"  ⚠️ {model1}과 {model2} 중 하나만 선택하는 것을 권장합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블 모델 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = load_file('./correlation/bert_cnn.json')\n",
    "second = load_file('./correlation/kobigbird_sd.json')\n",
    "third = load_file('./correlation/roberta_hz.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first - third: 0.674\n",
      "first - second: 0.488\n",
      "second - third: 0.452\n"
     ]
    }
   ],
   "source": [
    "predictions_dict = {\n",
    "    \"first\": first,\n",
    "    \"second\": second,\n",
    "    \"third\": third\n",
    "}\n",
    "answers = answers\n",
    "\n",
    "# 상관계수 계산\n",
    "correlation_matrix = calculate_error_correlations(predictions_dict, answers)\n",
    "\n",
    "# 높은 상관관계를 가진 모델 쌍 분석\n",
    "high_correlations = analyze_model_pairs(correlation_matrix, threshold=0)\n",
    "\n",
    "# 결과 출력\n",
    "for model1, model2, corr in high_correlations:\n",
    "    print(f\"{model1} - {model2}: {corr:.3f}\")\n",
    "    if corr > 0.7:\n",
    "        print(f\"  ⚠️ {model1}과 {model2} 중 하나만 선택하는 것을 권장합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = './resources/checkpoint/extraction/origin/hongzoh_roberta-large-qa-korquad-v1_batch32/predictions.json'\n",
    "#second = './resources/checkpoint/extraction/origin/hongzoh_roberta-large-qa-korquad-v2_batch32/predictions.json'\n",
    "second = './resources/checkpoint/extraction/origin/line1029_korquad-finetuned-roberta-large/predictions.json'\n",
    "third = './resources/checkpoint/extraction/origin/nlpotato_roberta_large_origin_added_korquad/predictions.json'\n",
    "first = load_file(first)\n",
    "second = load_file(second)\n",
    "third = load_file(third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first - third: 0.592\n",
      "second - third: 0.557\n",
      "first - second: 0.528\n"
     ]
    }
   ],
   "source": [
    "predictions_dict = {\n",
    "    \"first\": first,\n",
    "    \"second\": second,\n",
    "    \"third\": third\n",
    "}\n",
    "answers = answers\n",
    "\n",
    "# 상관계수 계산\n",
    "correlation_matrix = calculate_error_correlations(predictions_dict, answers)\n",
    "\n",
    "# 높은 상관관계를 가진 모델 쌍 분석\n",
    "high_correlations = analyze_model_pairs(correlation_matrix, threshold=0.5)\n",
    "\n",
    "# 결과 출력\n",
    "for model1, model2, corr in high_correlations:\n",
    "    print(f\"{model1} - {model2}: {corr:.3f}\")\n",
    "    if corr > 0.7:\n",
    "        print(f\"  ⚠️ {model1}과 {model2} 중 하나만 선택하는 것을 권장합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = './resources//predictions.json'\n",
    "second = './resources/checkpoint/extraction/origin/eeeyounglee_kpfbert-korquad-1/predictions.json'\n",
    "first = load_file(first)\n",
    "second = load_file(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first - second: 0.565\n"
     ]
    }
   ],
   "source": [
    "predictions_dict = {\n",
    "    \"first\": first,\n",
    "    \"second\": second,\n",
    "}\n",
    "answers = answers\n",
    "\n",
    "# 상관계수 계산\n",
    "correlation_matrix = calculate_error_correlations(predictions_dict, answers)\n",
    "\n",
    "# 높은 상관관계를 가진 모델 쌍 분석\n",
    "high_correlations = analyze_model_pairs(correlation_matrix, threshold=0.5)\n",
    "\n",
    "# 결과 출력\n",
    "for model1, model2, corr in high_correlations:\n",
    "    print(f\"{model1} - {model2}: {corr:.3f}\")\n",
    "    if corr > 0.7:\n",
    "        print(f\"  ⚠️ {model1}과 {model2} 중 하나만 선택하는 것을 권장합니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
